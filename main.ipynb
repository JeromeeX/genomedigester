{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(file_path):\n",
    "    \"\"\"\n",
    "    Reads a FASTA file and returns a dictionary where keys are the headers (chromosomes or enzyme names)\n",
    "    and values are the corresponding sequences.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        sequences = {}\n",
    "        header = None # Initiating header to None\n",
    "        sequence = []\n",
    "\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if header:\n",
    "                    sequences[header] = ''.join(sequence)\n",
    "                header = line[1:]  # Remove '>' character\n",
    "                sequence = []\n",
    "            else:\n",
    "                sequence.append(line.upper())\n",
    "        \n",
    "        # Add the last sequence\n",
    "        if header:\n",
    "            sequences[header] = ''.join(sequence)\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restriction_sites(file_path):\n",
    "    \"\"\"\n",
    "    Reads the enzyme file and returns a dictionary where keys are the enzymes and values are a list\n",
    "    consisting cutsite and the nick.\n",
    "    \"\"\"\n",
    "    enzymes = read_fasta(file_path)\n",
    "    for key in enzymes:\n",
    "        nick = enzymes[key].find(\"/\")\n",
    "        enzymes[key] = [enzymes[key].replace(\"/\", \"\").replace(\"N\", \"[ACTG]\").replace(\"Y\", \"[CT]\").replace(\"R\", \"[AG]\").replace(\"W\",\"[AT]\"), nick]\n",
    "        # Replace all the placeholders with the corresponding regex\n",
    "    return enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_restriction_sites(genome, enzyme):\n",
    "    \"\"\"\n",
    "    Finds restriction sites in the genome. Returns a dictionary where keys are headers (chromosomes)\n",
    "    and values are lists of positions of the restriction site.\n",
    "    \"\"\"\n",
    "    positions = {}\n",
    "    restriction_site = restriction_sites(\"test_enzyme.fa\")[enzyme]\n",
    "\n",
    "    for chr, seq in genome.items():\n",
    "        positions[chr] = [0]+ [restriction_site[1] + m.start() for m in re.finditer(restriction_site[0], seq)]\n",
    "        # Find all the restriction sites and add the nick to the position, add the first position of the chromosome\n",
    "        if positions[chr][-1] != len(seq):\n",
    "            positions[chr].append(len(seq))\n",
    "        # Add the last position of the chromosome\n",
    "\n",
    "    return positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fragment(sites, min_size, max_size):\n",
    "    \"\"\"\n",
    "    Input is a list of restriction sites, and the maximum and minimum size of the fragment,\n",
    "    output is a list of restriction sites inserted with random break sites.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    new_sites = sites.copy()  # Copy the original list to avoid modifying it\n",
    "    current_position = sites[0]\n",
    "\n",
    "    while current_position < sites[-1]:\n",
    "        current_position += random.randint(min_size, max_size)\n",
    "        if current_position < sites[-1]:\n",
    "            new_sites.append(current_position)\n",
    "\n",
    "    return sorted(new_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import matplotlib.pyplot as plt\n",
    "    from collections import Counter\n",
    "    import pandas as pd\n",
    "\n",
    "    genome_file = \"../genome_celegans.fa\"\n",
    "    enzyme_file = \"test_enzyme.fa\"\n",
    "\n",
    "    # Read genome and restriction enzyme sites\n",
    "    genome = read_fasta(genome_file)\n",
    "    enzymes = restriction_sites(enzyme_file)\n",
    "    \n",
    "    # Create a dictionary to store the restriction sites for the selected enzymes\n",
    "    #selected_enzymes = [enzyme.strip() for enzyme in input(\"Enter the names of the enzymes separated by commas (e.g., EcoRI, HindIII): \").split(',')]\n",
    "    selected_enzymes = \"EcoRI, HindIII\".split(',')\n",
    "    #selected_enzymes = \"DraI\".split(',')\n",
    "    # Find restriction s]ites for the selected enzymes and generate the selected_restriction_sites dictionary\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    selected_restriction_sites = defaultdict(set) # Use defaultdict to avoid key errors and store unique restriction sites\n",
    "    for enzyme_name in selected_enzymes:\n",
    "        enzyme_name = enzyme_name.strip() # Remove whitespaces\n",
    "        if enzyme_name in enzymes:\n",
    "            enzyme_sites = find_restriction_sites(genome, enzyme_name)\n",
    "            for chr, sites in enzyme_sites.items(): # Add the restriction sites to the selected_restriction_sites dictionary\n",
    "                selected_restriction_sites[chr].update(sites)\n",
    "        else:\n",
    "            print(\"{enzyme} not found!\".format(enzyme=enzyme_name))\n",
    "    \n",
    "    for chr in selected_restriction_sites: # Sort the restriction sites and convert the set to sorted list\n",
    "        selected_restriction_sites[chr] = sorted(list(selected_restriction_sites[chr]))\n",
    "    \n",
    "    # Simulate the fragmentation during genome DNA extraction\n",
    "    distances = []\n",
    "    for chr, sites in selected_restriction_sites.items():\n",
    "        for i in range(100):\n",
    "            sites_with_fragmentation = random_fragment(sites, 35000, 100000)\n",
    "            distances_in_chr = [sites_with_fragmentation[i+1] - sites_with_fragmentation[i] for i in range(len(sites_with_fragmentation)-1)]\n",
    "            distances.extend(distances_in_chr)\n",
    "\n",
    "\n",
    "    # Summarize the fragment sizes by printing the sum of the fragment sizes in each bin\n",
    "    bins = [i for i in range(0, 20000, 1)]\n",
    "    \n",
    "    # Make a pandas dataframe to store the fragment sizes and their counts. Using bins of size 1\n",
    "    distances_count = Counter(distances)\n",
    "\n",
    "    # Sum the counts of the fragment sizes in each bin\n",
    "    df = pd.DataFrame.from_dict(distances_count, orient='index').reset_index()\n",
    "    df.columns = ['size', 'count']\n",
    "\n",
    "    # df.to_csv(\"fragment_sizes.csv\", index=False)\n",
    "    df[\"bases\"] = df[\"size\"] * df[\"count\"]\n",
    "    \n",
    "    # Create an index column with the fragment sizes\n",
    "    df.set_index(\"size\", inplace=True)\n",
    "    \n",
    "    # Delete the count column\n",
    "    del df[\"count\"]\n",
    "    \n",
    "    # Convert the df index into bins\n",
    "    df = df.groupby(pd.cut(df.index, bins=bins)).sum()\n",
    "\n",
    "    # Change zeros and NaN to 1 to avoid log(0) error\n",
    "    df = df.replace(0, 1)\n",
    "    df = df.fillna(1)\n",
    "\n",
    "    # Change the index into an integer by converting the string into a list and taking the first element\n",
    "    df.index = [int(str(i)[1:-1].split(\",\")[1]) for i in df.index]\n",
    "\n",
    "    # Normalize the bases column\n",
    "    df[\"bases\"] = df[\"bases\"] / df[\"bases\"].sum() * 1000\n",
    "\n",
    "    # Plot the simulated gel electrophoresis\n",
    "    plt.figure(figsize=(2, 10))\n",
    "    plt.imshow(df, aspect='auto', cmap=\"gray\")\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(50, df.index[-1])\n",
    "\n",
    "    # set yticks from a list\n",
    "    ticks = [50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000, 2500, 3000, 4000, 5000, 6000, 8000, 10000]\n",
    "    plt.yticks(ticks, ticks)\n",
    "\n",
    "\n",
    "    plt.colorbar(label='DNA Amount (ng per µg)')\n",
    "    xlabel = \" + \".join(selected_enzymes)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Fragment Size (bp)')\n",
    "    plt.title(\"Simulated DNA Gel after \" + \" +\".join(selected_enzymes) + \" Digestion\")\n",
    "    #plt.savefig(\" +\".join(selected_enzymes) + \" Gel.jpg\", dpi=1000, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Make another plot based on df, with index as x and bases as y\n",
    "    import seaborn as sns\n",
    "\n",
    "    bins_new = [i for i in range(0, 20000, 15)]\n",
    "    df_new = df.groupby(pd.cut(df.index, bins=bins_new)).sum()\n",
    "    df_new[\"bases\"] = df_new[\"bases\"]/df_new[\"bases\"].sum() * 1000\n",
    "    df_new.index = [int(str(i)[1:-1].split(\",\")[1]) for i in df_new.index]\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.lineplot(x=df_new.index, y=df_new[\"bases\"])\n",
    "    #plt.xscale('log')\n",
    "    #plt.yscale('log')\n",
    "    plt.xlim(0, df_new.index[-1])\n",
    "    plt.ylim(0, df_new[\"bases\"].max() + 2)\n",
    "    plt.xlabel(\"Fragment Size (bp)\")\n",
    "    plt.ylabel(\"DNA Amount (ng per µg)\")\n",
    "    plt.title(\"Simulated Femto Pulse after \" + \" +\".join(selected_enzymes) + \" Digestion\")\n",
    "    # Annotate the data point with the highest DNA amount\n",
    "    plt.annotate(str(round(df_new[\"bases\"].idxmax())), xy=(df_new[\"bases\"].idxmax(), df_new[\"bases\"].max()), xytext=(df_new[\"bases\"].idxmax(), df_new[\"bases\"].max()*1.05),\n",
    "                 rotation=90, ha='center', va='bottom', color=\"blue\")\n",
    "    plt.savefig(\"ta299_femtopulse_\" + \" +\".join(selected_enzymes) + \".jpg\", dpi=1000)\n",
    "    plt.show()\n",
    "\n",
    "    return distances # Return the distances list to be used in the plot\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enzyme_iteration(genome_file, enzyme_file):\n",
    "    from collections import defaultdict\n",
    "    from collections import Counter\n",
    "    enzymes = restriction_sites(enzyme_file)\n",
    "    genome = read_fasta(genome_file)\n",
    "    iteration_result = {}\n",
    "\n",
    "    for enzyme in enzymes:\n",
    "        selected_restriction_sites = defaultdict(set) # Use defaultdict to avoid key errors and store unique restriction sites\n",
    "        enzyme_sites = find_restriction_sites(genome, enzyme)\n",
    "        for chr, sites in enzyme_sites.items():\n",
    "            selected_restriction_sites[chr].update(sites)\n",
    "        for chr in selected_restriction_sites:\n",
    "            selected_restriction_sites[chr] = sorted(list(selected_restriction_sites[chr]))\n",
    "\n",
    "        distances = []\n",
    "        for chr, sites in selected_restriction_sites.items():\n",
    "            for i in range(500):\n",
    "                sites_with_fragmentation = random_fragment(sites, 35000, 100000)\n",
    "                distances_in_chr = [sites_with_fragmentation[i+1] - sites_with_fragmentation[i] for i in range(len(sites_with_fragmentation)-1)]\n",
    "                distances.extend(distances_in_chr)\n",
    "        \n",
    "        distances_count = Counter(distances)\n",
    "        for size, count in distances_count.items():\n",
    "            distances_count[size] = size * count\n",
    "        max_proportion = max(distances_count.values())\n",
    "        for size, propor in distances_count.items():\n",
    "            if propor == max_proportion:\n",
    "                iteration_result[enzyme] = size\n",
    "    \n",
    "    return iteration_result\n",
    "\n",
    "enzyme_iteration(\"../genome_celegans.fa\", \"test_enzyme.fa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
